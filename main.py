from langchain_chroma.vectorstores import Chroma
from langchain_google_genai import GoogleGenerativeAIEmbeddings
import google.generativeai as genai
from dotenv import load_dotenv
import os

# Carregar vari√°veis de ambiente
load_dotenv()

# Configurar Gemini Pro
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))

# Caminho do banco de dados vetorial
caminho_db = "chroma"

# Template do prompt para RAG
prompt_template = """
Responda a pergunta do usu√°rio: {pergunta}

Com base nas informa√ß√µes a seguir:
{base_de_conhecimento}

Se voc√™ n√£o encontrar a resposta para a pergunta do usu√°rio nessas informa√ß√µes, 
responda "N√£o encontrei a informa√ß√£o requerida nos documentos fornecidos."

Responda em portugu√™s e seja claro e objetivo.
"""

def carregar_db():
    """Carrega o banco de dados vetorial"""
    try:
        funcao_embeddings = GoogleGenerativeAIEmbeddings(
            model="models/embedding-001",
            google_api_key=os.getenv('GOOGLE_API_KEY')
        )
        
        db = Chroma(persist_directory=caminho_db, embedding_function=funcao_embeddings)
        print("‚úÖ Banco de dados carregado com sucesso!")
        return db
    except Exception as e:
        print(f"‚ùå Erro ao carregar banco de dados: {e}")
        return None

def buscar_documentos_relevantes(db, pergunta, k=3):
    """Busca documentos relevantes no banco vetorial"""
    try:
        resultados = db.similarity_search_with_relevance_scores(pergunta, k=k)
        print(f"üîç Encontrados {len(resultados)} documentos")
        
        # Filtrar apenas resultados com relev√¢ncia > 0.7
        documentos_filtrados = [doc for doc, score in resultados if score > 0.7]
        
        if not documentos_filtrados:
            print("‚ö†Ô∏è Nenhum documento relevante com alta confian√ßa")
            # Se n√£o encontrar com alta relev√¢ncia, usar os 2 melhores mesmo assim
            documentos_filtrados = [doc for doc, score in resultados[:2]]
        
        # Combinar o conte√∫do dos documentos relevantes
        contexto = "\n\n".join([doc.page_content for doc in documentos_filtrados])
        return contexto
        
    except Exception as e:
        print(f"‚ùå Erro na busca: {e}")
        return ""

def gerar_resposta_gemini(pergunta, contexto):
    """Gera resposta usando Gemini Pro com o contexto dos documentos"""
    try:
        # Configurar o modelo
        model = genai.GenerativeModel('gemini-pro')
        
        # Criar o prompt completo
        prompt_completo = prompt_template.format(
            pergunta=pergunta,
            base_de_conhecimento=contexto
        )
        
        # Gerar resposta
        response = model.generate_content(
            prompt_completo,
            generation_config={
                'temperature': 0.1,
                'max_output_tokens': 500,
                'top_p': 0.8,
                'top_k': 10
            }
        )
        
        return response.text
        
    except Exception as e:
        print(f"‚ùå Erro ao gerar resposta: {e}")
        return "Desculpe, ocorreu um erro ao processar sua pergunta."

def main():
    """Fun√ß√£o principal do chatbot"""
    print("ü§ñ Chatbot RAG com Gemini Pro iniciado!")
    print("Digite 'sair' para encerrar.")
    print("=" * 50)
    
    # Carregar banco de dados
    db = carregar_db()
    if not db:
        print("‚ùå N√£o foi poss√≠vel carregar o banco de dados.")
        print("Certifique-se de que voc√™ executou o create_db.py primeiro.")
        return
    
    # Loop principal do chat
    while True:
        pergunta = input("\nüí¨ Sua pergunta: ").strip()
        
        if pergunta.lower() in ['sair', 'exit', 'quit']:
            print("üëã At√© logo!")
            break
        
        if not pergunta:
            print("Por favor, fa√ßa uma pergunta.")
            continue
        
        print("üîç Buscando informa√ß√µes relevantes...")
        
        # Buscar documentos relevantes
        contexto = buscar_documentos_relevantes(db, pergunta)
        
        if not contexto:
            print("‚ùå N√£o encontrei informa√ß√µes relevantes nos documentos.")
            continue
        
        print("ü§î Gerando resposta com Gemini Pro...")
        
        # Gerar resposta
        resposta = gerar_resposta_gemini(pergunta, contexto)
        
        print(f"\nü§ñ Resposta:\n{resposta}")
        print("-" * 50)

if __name__ == "__main__":
    # Verifica√ß√µes iniciais
    if not os.path.exists('.env'):
        print("‚ùå Arquivo .env n√£o encontrado!")
        print("Crie um arquivo .env com sua GOOGLE_API_KEY")
    
    elif not os.getenv('GOOGLE_API_KEY'):
        print("‚ùå GOOGLE_API_KEY n√£o encontrada no arquivo .env")
        print("1. Acesse: https://makersuite.google.com/app/apikey")
        print("2. Crie uma API key")
        print("3. Adicione no .env: GOOGLE_API_KEY=sua_chave")
    
    elif not os.path.exists(caminho_db):
        print(f"‚ùå Banco de dados '{caminho_db}' n√£o encontrado!")
        print("Execute primeiro o create_db.py para criar o banco.")
    
    else:
        main()